{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866d1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7e1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(\n",
    "    name=\"24winterdev\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5cf10db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1í•™ë…„ë„ ì§€ì› ìê²©ì´ ìˆë‚˜ìš”?</td>\n",
       "      <td>ì—ì½”ë…¸ë² ì´ì…˜ì€ ë‚˜ì´, íœ´í•™ ì—¬ë¶€, ì „ê³µì— ê´€ê³„ì—†ì´ ITì— ê´€ì‹¬ì´ ìˆê³  ì—´ì •ì´ ìˆë‹¤ë©´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ì—ì½”ë…¸ë² ì´ì…˜ì˜ ì°½ë¦½ ì—°ë„ëŠ” ì–¸ì œì¸ê°€ìš”?</td>\n",
       "      <td>ì—ì½”ë…¸ë² ì´ì…˜ì€ 2011ë…„ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>ì´ë²ˆ ë°ë¸Œ ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”?</td>\n",
       "      <td>ì˜¤í”„ë¼ì¸ ìœ„ì¹˜ëŠ” ì „ë‚¨ëŒ€í•™êµ ìŠ¤í† ë¦¬ì›€ì…ë‹ˆë‹¤! ì—ì½”ë…¸ë² ì´ì…˜ YouTube Live ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>ë„ˆì™€ ê·¸ë¦° ê¸°ë¦° ê·¸ë¦¼ì€ ì–´ë–¤ ë¶„ì•¼ì˜ í”„ë¡œì íŠ¸ì¸ê°€ìš”?</td>\n",
       "      <td>*23#íŒ€ì˜ ë„ˆì™€ ê·¸ë¦° ê¸°ë¦° ê·¸ë¦¼ì€ WEB í”„ë¡œì íŠ¸ë¡œ, ëŒ€í•™ìƒë“¤ì„ ìœ„í•œ ì§€ì—­ê¸°ë°˜ í€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>ì—ì½”ë…¸ë² ì´ì…˜ ë™ì•„ë¦¬ì˜ ì •ê¸° ëª¨ì„ ì¼ì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?</td>\n",
       "      <td>ê³ ì •ì ìœ¼ë¡œ ì •í•´ì§„ í™œë™ìœ¼ë¡œëŠ” ê¸ˆìš”ì¼ 17ì‹œì— ì§„í–‰ë˜ëŠ” ì£¼ê°„ ë°œí‘œê°€ ìˆìŠµë‹ˆë‹¤! ì´ì™¸ì—...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Question  \\\n",
       "212                1í•™ë…„ë„ ì§€ì› ìê²©ì´ ìˆë‚˜ìš”?   \n",
       "81            ì—ì½”ë…¸ë² ì´ì…˜ì˜ ì°½ë¦½ ì—°ë„ëŠ” ì–¸ì œì¸ê°€ìš”?   \n",
       "389                ì´ë²ˆ ë°ë¸Œ ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”?   \n",
       "465    ë„ˆì™€ ê·¸ë¦° ê¸°ë¦° ê·¸ë¦¼ì€ ì–´ë–¤ ë¶„ì•¼ì˜ í”„ë¡œì íŠ¸ì¸ê°€ìš”?   \n",
       "276  ì—ì½”ë…¸ë² ì´ì…˜ ë™ì•„ë¦¬ì˜ ì •ê¸° ëª¨ì„ ì¼ì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?   \n",
       "\n",
       "                                                Answer  \n",
       "212  ì—ì½”ë…¸ë² ì´ì…˜ì€ ë‚˜ì´, íœ´í•™ ì—¬ë¶€, ì „ê³µì— ê´€ê³„ì—†ì´ ITì— ê´€ì‹¬ì´ ìˆê³  ì—´ì •ì´ ìˆë‹¤ë©´...  \n",
       "81                           ì—ì½”ë…¸ë² ì´ì…˜ì€ 2011ë…„ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ :)  \n",
       "389  ì˜¤í”„ë¼ì¸ ìœ„ì¹˜ëŠ” ì „ë‚¨ëŒ€í•™êµ ìŠ¤í† ë¦¬ì›€ì…ë‹ˆë‹¤! ì—ì½”ë…¸ë² ì´ì…˜ YouTube Live ht...  \n",
       "465  *23#íŒ€ì˜ ë„ˆì™€ ê·¸ë¦° ê¸°ë¦° ê·¸ë¦¼ì€ WEB í”„ë¡œì íŠ¸ë¡œ, ëŒ€í•™ìƒë“¤ì„ ìœ„í•œ ì§€ì—­ê¸°ë°˜ í€...  \n",
       "276  ê³ ì •ì ìœ¼ë¡œ ì •í•´ì§„ í™œë™ìœ¼ë¡œëŠ” ê¸ˆìš”ì¼ 17ì‹œì— ì§„í–‰ë˜ëŠ” ì£¼ê°„ ë°œí‘œê°€ ìˆìŠµë‹ˆë‹¤! ì´ì™¸ì—...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv(\"econo_data.csv\", encoding='cp949')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3436a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce63d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "551it [00:24, 22.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 551/551 [00:00<00:00, 33759.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "metadatas = []\n",
    "embeddings = []\n",
    "\n",
    "for row in tqdm(data.iterrows()):\n",
    "    index = row[0]\n",
    "    query = row[1].Question\n",
    "    answer = row[1].Answer\n",
    "    \n",
    "    metadata = {\n",
    "        \"query\": query,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    \n",
    "    embedding = model.encode(query, normalize_embeddings=True)\n",
    "    \n",
    "    ids.append(str(index))\n",
    "    metadatas.append(metadata)\n",
    "    embeddings.append(embedding)\n",
    "    \n",
    "chunk_size = 1024  # í•œ ë²ˆì— ì²˜ë¦¬í•  chunk í¬ê¸° ì„¤ì •\n",
    "total_chunks = len(embeddings) // chunk_size + 1  # ì „ì²´ ë°ì´í„°ë¥¼ chunk ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ íšŸìˆ˜\n",
    "embeddings = [ e.tolist() for e in tqdm(embeddings)]  \n",
    "\n",
    "for chunk_idx in tqdm(range(total_chunks)):\n",
    "    start_idx = chunk_idx * chunk_size\n",
    "    end_idx = (chunk_idx + 1) * chunk_size\n",
    "    \n",
    "    # chunk ë‹¨ìœ„ë¡œ ë°ì´í„° ìë¥´ê¸°\n",
    "    chunk_embeddings = embeddings[start_idx:end_idx]\n",
    "    chunk_ids = ids[start_idx:end_idx]\n",
    "    chunk_metadatas = metadatas[start_idx:end_idx]\n",
    "    \n",
    "    # chunkë¥¼ collectionì— ì¶”ê°€\n",
    "    collection.add(embeddings=chunk_embeddings, ids=chunk_ids, metadatas=chunk_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ea314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8577f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question):\n",
    "    query_embeddings=model.encode(question, normalize_embeddings=True, convert_to_tensor=True)\n",
    "    \n",
    "    top_k = 5\n",
    "    distances, indices = index.search(np.expand_dims(query_embeddings, axis=0), top_k)\n",
    "    \n",
    "    temp = data.iloc[indices[0]]\n",
    "    temp['distances'] = distances[0]\n",
    "    similar = temp[temp['distances'] < 1.1]\n",
    "    \n",
    "    result = {'Question' : similar['Question'].tolist(),\n",
    "             'Answer' : similar['Answer'].tolist()}\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ì—ì½”ë…¸ë² ì´ì…˜ì´ë¼ëŠ” ë™ì•„ë¦¬ì˜ ë¬¸ì˜ í•´ê²°ì„ ë„ì™€ì£¼ì„¸ìš”. You are an intelligent assistant helping the users with their questions\n",
    "    Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
    "    The instructions should be in Korean. Reply via text only\n",
    "Â \n",
    "    CONTEXT:Â \n",
    "    {result}\n",
    "Â \n",
    "    QUESTION:\n",
    "    {question}\n",
    "    \n",
    "    Do not try to make up an answer:\n",
    "     - If the answer to the question cannot be determined from the context alone, say \"í•´ë‹¹ ì§ˆë¬¸ì€ https://econovation.kr/contact í˜¹ì€ ì—ì½”ë…¸ë² ì´ì…˜ ì¹´ì¹´ì˜¤í†¡ ì±„ë„ https://pf.kakao.com/_laTLsë¡œ ë¬¸ì˜ì£¼ì„¸ìš”!\"\n",
    "     - If the context is empty, just say \"í˜„ì¬ ì„œë¹„ìŠ¤ ì¤€ë¹„ì¤‘ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.\"\n",
    "     \n",
    "    Strictly Use ONLY the following pieces of context to answer the question at the end.\n",
    "    Helpful Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d010e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'openai_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea6ac516",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50fa225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(message, history):\n",
    "    message = retriever(message)\n",
    "    \n",
    "    history_langchain_format = []\n",
    "    \n",
    "    for human, ai in history:\n",
    "                history_langchain_format.append(HumanMessage(content=human))\n",
    "                history_langchain_format.append(AIMessage(content=ai))\n",
    "    \n",
    "    history_langchain_format.append(HumanMessage(content=message))\n",
    "    gpt_response = llm(history_langchain_format)\n",
    "    return gpt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79b499bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://31adfc878488daa667.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://31adfc878488daa667.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kt826\\AppData\\Local\\Temp\\ipykernel_13040\\3337519297.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['distances'] = distances[0]\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(\n",
    "        fn=response,\n",
    "        textbox=gr.Textbox(placeholder=\"ëŒ€í™”ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\", container=False, scale=7),\n",
    "        title=\"ECONOVATION CHATBOT\",\n",
    "        examples=[[\"ì—ì½”ë…¸ë² ì´ì…˜ì—ì„œëŠ” ì–´ë–¤ í™œë™ì„ í•  ìˆ˜ ìˆë‚˜ìš”?\"], [\"ì–´ë–»ê²Œ ì§€ì›í•  ìˆ˜ ìˆë‚˜ìš”?\"], [\"í˜„ì¬ëŠ” ëª‡ ê¸°ìˆ˜ê¹Œì§€ ìˆì–´?\"]],\n",
    "        retry_btn=\"ë‹¤ì‹œë³´ë‚´ê¸° â†©\",\n",
    "        undo_btn=\"ì§€ë‚œ ëŒ€í™” ì‚­ì œ âŒ\",\n",
    "        clear_btn=\"ì „ì²´ ëŒ€í™” ì‚­ì œ ğŸ’«\",\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3fecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
